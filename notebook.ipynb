{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to prunning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning is a set of technics that allow for network size reduction.\n",
    "\n",
    "The basic apprach is based on weights values and remove connections with small weights.\n",
    "\n",
    "There is many different aproaches to prunning for example:\n",
    "\n",
    "    1) statical weights analysis to check importance of input channel,\n",
    "\n",
    "    2) statical weights analysis to check filters simmilarity,\n",
    "\n",
    "    3) prunning by trainable parameters as channels importance levels.\n",
    "\n",
    "This tutorial presents second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "# local_utils file contains util functions for training or display\n",
    "# CHECK IT\n",
    "import local_utils as lu\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "def set_random_seed(seed:int = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 938\n",
      "len(test_loader) = 157\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2304x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "set_random_seed(0)\n",
    "\n",
    "train_dataset = datasets.MNIST('data', \n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "test_dataset = datasets.MNIST('data', \n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "\n",
    "print(\"len(train_loader) =\", len(train_loader))\n",
    "print(\"len(test_loader) =\", len(test_loader))\n",
    "\n",
    "plt.gray()\n",
    "loader = train_loader\n",
    "for X, y in loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    ROWS, COLS = 1, 8\n",
    "    fig, axs = plt.subplots(ROWS, COLS)\n",
    "    fig.set_size_inches(COLS*4,ROWS*4)\n",
    "    axs = np.array(axs).flatten().tolist()\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        img = X[i,...]\n",
    "        class_label = loader.dataset.classes[y[i]]\n",
    "        ax.imshow(img.permute(1,2,0))\n",
    "    plt.show()\n",
    "            \n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network paramerters number: 1863690\n",
      "Epoch 1 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 267.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 271.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1: loss=2.3015 acc=0.1121 val_loss=2.2980 val_acc=0.1028\n",
      "Epoch 1 / 30: FINISHED\n",
      "\n",
      "Epoch 2 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 270.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 271.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 2: loss=2.2918 acc=0.1305 val_loss=2.2703 val_acc=0.1518\n",
      "Epoch 2 / 30: FINISHED\n",
      "\n",
      "Epoch 3 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 266.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 250.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 3: loss=2.1816 acc=0.3143 val_loss=2.0202 val_acc=0.5422\n",
      "Epoch 3 / 30: FINISHED\n",
      "\n",
      "Epoch 4 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 260.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 264.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 4: loss=1.9086 acc=0.5997 val_loss=1.8296 val_acc=0.6432\n",
      "Epoch 4 / 30: FINISHED\n",
      "\n",
      "Epoch 5 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 264.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 268.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 5: loss=1.8016 acc=0.6373 val_loss=1.7772 val_acc=0.6521\n",
      "Epoch 5 / 30: FINISHED\n",
      "\n",
      "Epoch 6 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 278.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 268.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 6: loss=1.7637 acc=0.6483 val_loss=1.7495 val_acc=0.6573\n",
      "Epoch 6 / 30: FINISHED\n",
      "\n",
      "Epoch 7 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 266.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 270.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 7: loss=1.7388 acc=0.6525 val_loss=1.7271 val_acc=0.6595\n",
      "Epoch 7 / 30: FINISHED\n",
      "\n",
      "Epoch 8 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 260.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 262.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 8: loss=1.7186 acc=0.6523 val_loss=1.7081 val_acc=0.6618\n",
      "Epoch 8 / 30: FINISHED\n",
      "\n",
      "Epoch 9 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 264.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 271.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 9: loss=1.7016 acc=0.6601 val_loss=1.6919 val_acc=0.6752\n",
      "Epoch 9 / 30: FINISHED\n",
      "\n",
      "Epoch 10 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 262.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 267.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10: loss=1.6856 acc=0.6872 val_loss=1.6747 val_acc=0.7115\n",
      "Epoch 10 / 30: FINISHED\n",
      "\n",
      "Epoch 11 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 259.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 269.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 11: loss=1.6684 acc=0.7330 val_loss=1.6573 val_acc=0.7527\n",
      "Epoch 11 / 30: FINISHED\n",
      "\n",
      "Epoch 12 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 260.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 266.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 12: loss=1.6539 acc=0.7662 val_loss=1.6446 val_acc=0.7756\n",
      "Epoch 12 / 30: FINISHED\n",
      "\n",
      "Epoch 13 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 265.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 265.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 13: loss=1.6438 acc=0.7870 val_loss=1.6353 val_acc=0.7903\n",
      "Epoch 13 / 30: FINISHED\n",
      "\n",
      "Epoch 14 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 260.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 265.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 14: loss=1.6356 acc=0.8029 val_loss=1.6271 val_acc=0.7993\n",
      "Epoch 14 / 30: FINISHED\n",
      "\n",
      "Epoch 15 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 264.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 270.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 15: loss=1.6279 acc=0.8129 val_loss=1.6189 val_acc=0.8045\n",
      "Epoch 15 / 30: FINISHED\n",
      "\n",
      "Epoch 16 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 275.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 274.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 16: loss=1.6204 acc=0.8160 val_loss=1.6118 val_acc=0.8043\n",
      "Epoch 16 / 30: FINISHED\n",
      "\n",
      "Epoch 17 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 270.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 272.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 17: loss=1.6142 acc=0.8129 val_loss=1.6064 val_acc=0.8040\n",
      "Epoch 17 / 30: FINISHED\n",
      "\n",
      "Epoch 18 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 270.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 272.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 18: loss=1.6092 acc=0.8098 val_loss=1.6020 val_acc=0.8032\n",
      "Epoch 18 / 30: FINISHED\n",
      "\n",
      "Epoch 19 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 270.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 276.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 19: loss=1.6051 acc=0.8078 val_loss=1.5983 val_acc=0.8032\n",
      "Epoch 19 / 30: FINISHED\n",
      "\n",
      "Epoch 20 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 267.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 272.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 20: loss=1.6015 acc=0.8072 val_loss=1.5950 val_acc=0.8035\n",
      "Epoch 20 / 30: FINISHED\n",
      "\n",
      "Epoch 21 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 267.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 270.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 21: loss=1.5984 acc=0.8071 val_loss=1.5921 val_acc=0.8052\n",
      "Epoch 21 / 30: FINISHED\n",
      "\n",
      "Epoch 22 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 266.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 273.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 22: loss=1.5955 acc=0.8076 val_loss=1.5895 val_acc=0.8064\n",
      "Epoch 22 / 30: FINISHED\n",
      "\n",
      "Epoch 23 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 265.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 266.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 23: loss=1.5929 acc=0.8087 val_loss=1.5871 val_acc=0.8086\n",
      "Epoch 23 / 30: FINISHED\n",
      "\n",
      "Epoch 24 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 263.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 268.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 24: loss=1.5906 acc=0.8097 val_loss=1.5849 val_acc=0.8096\n",
      "Epoch 24 / 30: FINISHED\n",
      "\n",
      "Epoch 25 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 252.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 261.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 25: loss=1.5883 acc=0.8108 val_loss=1.5828 val_acc=0.8118\n",
      "Epoch 25 / 30: FINISHED\n",
      "\n",
      "Epoch 26 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 266.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 271.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 26: loss=1.5863 acc=0.8126 val_loss=1.5808 val_acc=0.8143\n",
      "Epoch 26 / 30: FINISHED\n",
      "\n",
      "Epoch 27 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 264.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 251.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 27: loss=1.5844 acc=0.8141 val_loss=1.5790 val_acc=0.8161\n",
      "Epoch 27 / 30: FINISHED\n",
      "\n",
      "Epoch 28 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 267.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 283.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 28: loss=1.5825 acc=0.8157 val_loss=1.5773 val_acc=0.8180\n",
      "Epoch 28 / 30: FINISHED\n",
      "\n",
      "Epoch 29 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 275.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 269.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 29: loss=1.5808 acc=0.8173 val_loss=1.5757 val_acc=0.8195\n",
      "Epoch 29 / 30: FINISHED\n",
      "\n",
      "Epoch 30 / 30: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:03, 266.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 272.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 30: loss=1.5792 acc=0.8188 val_loss=1.5741 val_acc=0.8209\n",
      "Epoch 30 / 30: FINISHED\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape=(1,28,28), \n",
    "                 num_of_classes=10,\n",
    "                 hidden_1_size = 1024,\n",
    "                 hidden_2_size = 1024,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        input_len = torch.prod(torch.tensor(input_shape))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden_1 = nn.Linear(input_len, hidden_1_size)\n",
    "        self.hidden_2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
    "        self.last_layer = nn.Linear(hidden_2_size, num_of_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        x = self.hidden_1(x)\n",
    "        x = self.sigm(x)\n",
    "        x = self.hidden_2(x)\n",
    "        x = self.sigm(x)\n",
    "        x = self.last_layer(x)\n",
    "        x = self.sigm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "set_random_seed(0)\n",
    "net = NeuralNetwork().to(device)\n",
    "net_param_number = lu.count_params(net)\n",
    "print(f\"Network paramerters number: {net_param_number}\")\n",
    "\n",
    "set_random_seed(0)\n",
    "metric = lu.AccuracyMetic()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "set_random_seed(0)\n",
    "net, history = lu.training(net, train_loader, test_loader, criterion, metric, optimizer, 5, 30, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract state dict (and name it - `sd`) from trained model.\n",
    "\n",
    "Create second dictionary `sd_2` and fill it with copies of parameters from extracted state dictionary.\n",
    "\n",
    "Print parameters names, shapes and statistics: min, max, std, mean for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_1.weight, torch.Size([1024, 784]), min=-0.17751307785511017, max=0.18090690672397614, mean=-0.00022693403298035264, var=0.0007318296120502055, std=0.027052350342273712\n",
      "hidden_1.bias, torch.Size([1024]), min=-0.06644146889448166, max=0.07040654122829437, mean=-0.0011242736363783479, var=0.000566539412830025, std=0.02380208857357502\n",
      "hidden_2.weight, torch.Size([1024, 1024]), min=-0.11891487240791321, max=0.12396501749753952, mean=-0.0006517586298286915, var=0.0005572724621742964, std=0.023606618866324425\n",
      "hidden_2.bias, torch.Size([1024]), min=-0.03590383008122444, max=0.03526987507939339, mean=-0.00011114070366602391, var=0.0003205725515726954, std=0.01790454052388668\n",
      "last_layer.weight, torch.Size([10, 1024]), min=-0.49845197796821594, max=0.4577457904815674, mean=-0.026112252846360207, var=0.020633583888411522, std=0.14364394545555115\n",
      "last_layer.bias, torch.Size([10]), min=-0.09622375667095184, max=-0.006978764198720455, mean=-0.03891773894429207, var=0.0007154582417570055, std=0.026748051866889\n"
     ]
    }
   ],
   "source": [
    "sd = {\"model\" : net.state_dict(), \"opt\" : optimizer.state_dict()}\n",
    "\n",
    "sd_2 = sd\n",
    "\n",
    "for name, tensor in sd[\"model\"].items():\n",
    "    print(f\"{name}, {tensor.size()}, min={torch.min(tensor)}, max={torch.max(tensor)}, mean={torch.mean(tensor)}, var={torch.var(tensor)}, std={torch.std(tensor)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function `get_mask`, which takes arguments:\n",
    "    - `parameter` - tensor of weights\n",
    "    - `threshold` - threashold of filters (weights for single out channel) corelation\n",
    "\n",
    "Function shoud:\n",
    "1) standardize each row by it's mean and standard deviation and small value epsilon = 1e-6.\n",
    "    - this step is not necessary, you can try different version: with and without standardization \n",
    "2) normalize each row by it's Euclidian norm.\n",
    "3) calculate corelation matrix between filters (rows):\n",
    "    - `torch.matmul`\n",
    "    - `torch.transpose`\n",
    "4) threshold absolute corelation matrix with given parameter `threshold`\n",
    "5) create mask of matrix elements where coloumn idx is higher than row idx - over diagonal matrix.\n",
    "    - `torch.meshgrid`\n",
    "6) create mask of intersection of both masks from 4) and 5)\n",
    "7) crete mask of columns where there are only zero elements.\n",
    "8) return mask as mask of filters to leave untouched (True) and fileter to remove (False).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "def get_mask(parameter: torch.Tensor, threshold: float):\n",
    "    \n",
    "    parameter = normalize(parameter)\n",
    "\n",
    "    corr = torch.matmul(parameter, torch.transpose(parameter, 0, 1))\n",
    "\n",
    "    corr_mask = corr.abs() > threshold\n",
    "\n",
    "    row_idx, col_idx = torch.meshgrid(torch.arange(0,corr.shape[0]), torch.arange(0,corr.shape[0]),)\n",
    "\n",
    "    analysis_mask = col_idx > row_idx\n",
    "\n",
    "    filters_correlation = corr_mask * analysis_mask.to(parameter.device)\n",
    "\n",
    "    channels_mask = filters_correlation.sum(0) == 0\n",
    "\n",
    "    return channels_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate masks for both hidden weights from `sd` dict.\n",
    "\n",
    "Hint: work on copy of weights - `torch.Tensor.clone` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = torch.Tensor.clone(list(sd[\"model\"].items())[0][1])\n",
    "h2 =torch.Tensor.clone(list(sd[\"model\"].items())[0][2])\n",
    "\n",
    "\n",
    "h1_mask = get_mask(h1, 0.5)\n",
    "h2_mask = get_mask(h2, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Slice weights of hidden layers based on created masks.\n",
    "\n",
    "Resulted weights assign to proper weight in `sd_2`.\n",
    "\n",
    "Print shapes of weights.\n",
    "\n",
    "Note: Prunning of channels one layer affects to next one layer, but not to the previous layer.\n",
    "\n",
    "Note: first layer must contain the same number of input channels.\n",
    " \n",
    "Note: last layer must contain the same number of output channels.\n",
    "\n",
    "Hint: For slicing on few dimensions, use it separately on results of previous dim slice.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1021, 784])\n",
      "torch.Size([883, 1021])\n",
      "torch.Size([10, 883])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bias prunning: slice biases of hidden layers with layers masks.\n",
    "\n",
    "Note: bias is related with layer output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1021])\n",
      "torch.Size([883])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Instiante second `NeuralNetwork` with hidden size defined by proper mask size.\n",
    "\n",
    "Initialize network with `sd_2`.\n",
    "\n",
    "Print number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712751"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculate accuracy and loss for training and validation datasets.\n",
    "\n",
    "P.S. \n",
    "```\n",
    "lu.train_test_pass:\n",
    "\n",
    "optimizer=None,\n",
    "update_period=None,\n",
    "mode='test',\n",
    "device=device\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:08, 115.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.620261589050293 0.8059166666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:01, 117.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6104534406661988 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. *Aditional: Try 5 different thresholds for `get_mask` function.\n",
    "\n",
    "Print resulted sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Additional: Fine tune pruned model (`net_2`) - train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. You can leave a feedback, if you want :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Exercises please upload this file (*.ipynb) to UPEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f8983bddda93f81dfa77202df1e7f4d1cde96e239aa7ad80697fb7e3c19a16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
