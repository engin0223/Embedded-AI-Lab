{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN pruning and quantization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization allows for decreasing data memory size necessary to store them.\n",
    "\n",
    "Also allows for faster computation with dedicated devices like embedded GPU and FPGA.\n",
    "\n",
    "Applying quantization on continues data creates regions of attraction.\n",
    "\n",
    "Values from some range are assigned to proper value that represents that range.\n",
    "\n",
    "That also increase the level of correlation between quantized filters, \n",
    "\n",
    "so allows for more effective pruning.\n",
    "\n",
    "That results with much more smaller network than at the beginning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "1.13.0+cu117\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List, Tuple, Dict\n",
    "from copy import deepcopy\n",
    "\n",
    "# local_utils file contains util functions for training or display\n",
    "# CHECK IT\n",
    "import local_utils as lu\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "def set_random_seed(seed:int = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 938\n",
      "len(test_loader) = 157\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2304x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "set_random_seed(0)\n",
    "\n",
    "train_dataset = datasets.MNIST('data', \n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "test_dataset = datasets.MNIST('data', \n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "\n",
    "print(\"len(train_loader) =\", len(train_loader))\n",
    "print(\"len(test_loader) =\", len(test_loader))\n",
    "\n",
    "plt.gray()\n",
    "loader = train_loader\n",
    "for X, y in loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    ROWS, COLS = 1, 8\n",
    "    fig, axs = plt.subplots(ROWS, COLS)\n",
    "    fig.set_size_inches(COLS*4,ROWS*4)\n",
    "    axs = np.array(axs).flatten().tolist()\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        img = X[i,...]\n",
    "        class_label = loader.dataset.classes[y[i]]\n",
    "        ax.imshow(img.permute(1,2,0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network definition and training\n",
    "\n",
    "Run network training - it spends very long time, so for only your code check you can run only one epoch.\n",
    "\n",
    "When you check your code back to 30 epochs :) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN out map shape = [32, 3, 3]\n",
      "CNN out map numel = 288\n",
      "Network paramerters number: 30959\n",
      "Epoch 1 / 1: STARTED\n",
      "TRAINING"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:21, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:02, 58.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1: loss=1.9598 acc=0.5037 val_loss=1.7891 val_acc=0.6712\n",
      "Epoch 1 / 1: FINISHED\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from brevitas.nn import QuantConv2d, QuantIdentity\n",
    "from brevitas.quant.scaled_int import Int8WeightPerTensorFloat, \\\n",
    "    Int8BiasPerTensorFloatInternalScaling, Int8ActPerTensorFloat\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape=(1,28,28), \n",
    "                 num_of_classes=10,\n",
    "                 channels = [16,32,64,128], # number of conv filters \n",
    "                 ksize   =  [3, 3, 3, 3], # kernels sizes\n",
    "                 padding =  [1, 1, 0, 0], # padding sizes\n",
    "                 max_pool = [1, 1, 0, 0], # use maxpool after conv or not\n",
    "                 quantize=True,\n",
    "                 bit_width=4\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        channels = [input_shape[0]]+channels\n",
    "        padding = [1,1,0,0]\n",
    "        max_pool = [1,1,0,0]\n",
    "        \n",
    "        if quantize:\n",
    "            input_quant = QuantIdentity(Int8ActPerTensorFloat, min_val=-1.0, max_val=1.0, bit_width=bit_width)\n",
    "        else:\n",
    "            input_quant = QuantIdentity(None)\n",
    "        \n",
    "        layers = []\n",
    "        self.conv_layers = []\n",
    "        map_shape = [input_shape[0],input_shape[1],input_shape[2]]\n",
    "        for i, (ch_in, ch_out, ks, p, mp) in enumerate(zip(channels[:-1],\n",
    "                                                       channels[1:],\n",
    "                                                       ksize,\n",
    "                                                       padding,\n",
    "                                                       max_pool)):\n",
    "            conv = QuantConv2d(ch_in, ch_out, ks, padding=p, bias=True, \n",
    "                               weight_quant=Int8WeightPerTensorFloat if quantize else None,\n",
    "                               bias_quant=Int8BiasPerTensorFloatInternalScaling if quantize else None,\n",
    "                               weight_bit_width=bit_width,\n",
    "                               bias_bit_width=bit_width,\n",
    "                               return_quant_tensor=False\n",
    "                               )\n",
    "            # shape modification\n",
    "            map_shape[0] = ch_out\n",
    "            map_shape[1] = map_shape[1] - 2*(ks//2 - p)\n",
    "            map_shape[2] = map_shape[2] - 2*(ks//2 - p)\n",
    "            \n",
    "            # store conv layers for further analysis and prunning\n",
    "            self.conv_layers.append(conv)\n",
    "            # add to all layers\n",
    "            layers.append(conv)\n",
    "            \n",
    "            if quantize:\n",
    "                out_quant = QuantIdentity(Int8ActPerTensorFloat, min_val=-1.0, max_val=1.0, bit_width=bit_width)\n",
    "            else:\n",
    "                out_quant = QuantIdentity(None)\n",
    "            \n",
    "            layers.append(out_quant)\n",
    "            relu = nn.ReLU()\n",
    "            layers.append(relu)\n",
    "            \n",
    "            if mp:\n",
    "                maxpool = nn.MaxPool2d(2,2)\n",
    "                # shape modification\n",
    "                map_shape[1] = map_shape[1] // 2\n",
    "                map_shape[2] = map_shape[2] // 2\n",
    "                layers.append(maxpool)\n",
    "        \n",
    "        self.CNN = nn.Sequential(input_quant, *tuple(layers))\n",
    "        \n",
    "        CNN_flatten_len = torch.prod(torch.tensor(map_shape))\n",
    "        print(f\"CNN out map shape = {map_shape}\")\n",
    "        print(f\"CNN out map numel = {CNN_flatten_len}\")\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.FC = nn.Linear(CNN_flatten_len, num_of_classes)\n",
    "        self.sm = nn.Softmax(1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.CNN(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.FC(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "\n",
    "set_random_seed(0)\n",
    "net = NeuralNetwork(input_shape=(1,28,28), \n",
    "                    num_of_classes=10,\n",
    "                    channels = [32,32,32,32], # number of conv filters \n",
    "                    ksize   =  [3, 3, 3, 3], # kernels sizes\n",
    "                    padding =  [1, 1, 0, 0], # padding sizes\n",
    "                    max_pool = [1, 1, 0, 0], # use maxpool after conv or not\n",
    "                    quantize=True\n",
    "                    ).to(device)\n",
    "net_param_number = lu.count_params(net)\n",
    "print(f\"Network paramerters number: {net_param_number}\")\n",
    "\n",
    "set_random_seed(0)\n",
    "metric = lu.AccuracyMetic()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.8, weight_decay=0.0001)\n",
    "\n",
    "set_random_seed(0)\n",
    "net, history = lu.training(net, train_loader, test_loader, criterion, metric, optimizer, 5, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract state dict from each conv layer (`net.conv_layers` is a list of Conv2d submodules) and store it in a list `state_dicts_float`.\n",
    "\n",
    "Create second list `state_dicts_quant` with the same structure, \n",
    "\n",
    "but extract weights and biases after applied quantization (`.quant_weight()`, `.quant_bias()` -> `QuantTensor` - extract float tensor from it).\n",
    "\n",
    "Also create `state_dicts_quant_2` as a copy of `state_dicts_quant` elements - deep copy.\n",
    "\n",
    "Print layer index (in list) and shapes of weights and biases.\n",
    "\n",
    "Extract state dict of FC subnetwork. \n",
    "Store it as `sd_fc` and copy to `sd_fc_2`. \n",
    "Print weight and bias shapes for FC layer.\n",
    "\n",
    "\n",
    "Compare (display Sum of Absolute Difference value) weight for first convolution before(float) and after quantization.\n",
    "\n",
    "Note: state dict of Conv2d and QuantConv2d contains: `weight` and `bias` (optional) keys only.\n",
    "\n",
    "Remember about `torch.no_grad()` context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_0 = QuantTensor(value=tensor([[[[-0.0000,  0.1627, -0.2440],\n",
      "          [-0.2440, -0.1627,  0.0813],\n",
      "          [ 0.0000,  0.2440, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0813, -0.0813, -0.0813],\n",
      "          [-0.3253, -0.2440, -0.0813],\n",
      "          [ 0.0000,  0.1627,  0.2440]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627, -0.0813,  0.2440],\n",
      "          [ 0.3253,  0.0000,  0.4067],\n",
      "          [-0.0813,  0.0813,  0.4067]]],\n",
      "\n",
      "\n",
      "        [[[-0.3253, -0.2440, -0.0813],\n",
      "          [-0.1627,  0.3253, -0.2440],\n",
      "          [-0.1627, -0.2440, -0.3253]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627,  0.3253,  0.2440],\n",
      "          [ 0.2440,  0.0813, -0.1627],\n",
      "          [ 0.0813, -0.3253, -0.3253]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627,  0.4067,  0.4067],\n",
      "          [-0.0813,  0.1627,  0.4880],\n",
      "          [ 0.4067,  0.3253,  0.2440]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440, -0.1627,  0.0813],\n",
      "          [-0.2440, -0.2440, -0.1627],\n",
      "          [ 0.1627,  0.1627, -0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.2440, -0.0813],\n",
      "          [ 0.0813,  0.1627,  0.2440],\n",
      "          [ 0.4067, -0.1627, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3253,  0.4880,  0.4067],\n",
      "          [ 0.4880,  0.3253, -0.2440],\n",
      "          [ 0.2440, -0.0813, -0.3253]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440,  0.2440, -0.3253],\n",
      "          [ 0.0813, -0.0813, -0.0813],\n",
      "          [-0.1627,  0.1627, -0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.2440,  0.2440],\n",
      "          [ 0.1627, -0.3253, -0.2440],\n",
      "          [ 0.2440,  0.0813, -0.3253]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627,  0.3253,  0.2440],\n",
      "          [-0.1627, -0.0813, -0.3253],\n",
      "          [-0.0000, -0.2440, -0.2440]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0813, -0.1627],\n",
      "          [ 0.2440, -0.2440,  0.3253],\n",
      "          [ 0.2440, -0.2440, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0813,  0.0813,  0.1627],\n",
      "          [ 0.1627,  0.0813, -0.1627],\n",
      "          [ 0.1627, -0.3253, -0.2440]]],\n",
      "\n",
      "\n",
      "        [[[-0.0813, -0.1627, -0.0813],\n",
      "          [-0.2440, -0.0813,  0.0813],\n",
      "          [-0.2440, -0.0000,  0.2440]]],\n",
      "\n",
      "\n",
      "        [[[-0.0813,  0.0813,  0.0813],\n",
      "          [ 0.1627,  0.4880,  0.5693],\n",
      "          [ 0.3253,  0.5693,  0.1627]]],\n",
      "\n",
      "\n",
      "        [[[-0.3253, -0.2440,  0.2440],\n",
      "          [-0.0813, -0.2440, -0.3253],\n",
      "          [-0.3253, -0.3253, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.1627, -0.3253],\n",
      "          [ 0.1627, -0.2440, -0.0813],\n",
      "          [-0.1627, -0.0813, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.3253, -0.3253,  0.0000],\n",
      "          [-0.0000, -0.1627,  0.2440],\n",
      "          [-0.3253, -0.0000,  0.4067]]],\n",
      "\n",
      "\n",
      "        [[[-0.0813,  0.4067,  0.2440],\n",
      "          [-0.3253,  0.3253,  0.0813],\n",
      "          [-0.1627,  0.3253, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0813, -0.0000,  0.3253],\n",
      "          [ 0.0813,  0.2440,  0.1627],\n",
      "          [-0.0813, -0.0000, -0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440,  0.3253,  0.3253],\n",
      "          [-0.1627,  0.0813, -0.1627],\n",
      "          [-0.1627, -0.1627,  0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627, -0.0000,  0.0000],\n",
      "          [ 0.2440, -0.2440, -0.2440],\n",
      "          [-0.1627,  0.2440, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4067,  0.2440,  0.0813],\n",
      "          [ 0.0813,  0.0813,  0.1627],\n",
      "          [-0.0000,  0.0813,  0.1627]]],\n",
      "\n",
      "\n",
      "        [[[-0.2440, -0.1627,  0.3253],\n",
      "          [-0.2440, -0.0000,  0.4067],\n",
      "          [ 0.0813,  0.0000, -0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440, -0.2440, -0.1627],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.3253,  0.0813,  0.3253]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627, -0.2440,  0.0813],\n",
      "          [-0.2440, -0.1627,  0.0813],\n",
      "          [ 0.1627,  0.2440, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0813,  0.2440, -0.3253],\n",
      "          [ 0.3253, -0.3253, -0.0000],\n",
      "          [-0.0000, -0.1627,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440, -0.0813, -0.1627],\n",
      "          [-0.1627, -0.3253,  0.1627],\n",
      "          [-0.1627, -0.2440, -0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2440,  0.3253,  0.4067],\n",
      "          [ 0.3253,  0.1627,  0.0813],\n",
      "          [ 0.2440,  0.4880,  0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.0813, -0.1627, -0.3253],\n",
      "          [ 0.0813, -0.1627, -0.3253],\n",
      "          [ 0.3253, -0.2440, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.0000, -0.3253],\n",
      "          [-0.1627,  0.3253,  0.0813],\n",
      "          [ 0.3253, -0.0000,  0.1627]]]], device='cuda:0'), scale=tensor(0.0813, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32, 1, 3, 3]),\n",
      "bias_0 = QuantTensor(value=tensor([-0.0699,  0.0350, -0.0699,  0.0699,  0.2098,  0.1049, -0.0699, -0.1049,\n",
      "         0.1398, -0.2447,  0.1049, -0.1049, -0.1049,  0.1398, -0.1748,  0.0350,\n",
      "         0.0000, -0.2447,  0.1748,  0.0699,  0.1049,  0.0350, -0.2797, -0.0000,\n",
      "         0.1398, -0.0699,  0.1049,  0.2447, -0.1748,  0.0000,  0.2447,  0.0350],\n",
      "       device='cuda:0'), scale=tensor(0.0350, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32])\n",
      "weight_1 = QuantTensor(value=tensor([[[[-0.0000,  0.0000, -0.0465],\n",
      "          [-0.0000,  0.0465,  0.0698],\n",
      "          [ 0.0233,  0.0000,  0.0233]],\n",
      "\n",
      "         [[-0.0233, -0.0465, -0.0465],\n",
      "          [ 0.0465,  0.0233, -0.0233],\n",
      "          [ 0.0000,  0.0465,  0.0698]],\n",
      "\n",
      "         [[ 0.0698,  0.0465, -0.0698],\n",
      "          [ 0.0233,  0.0465,  0.0000],\n",
      "          [ 0.0233,  0.0465,  0.0233]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0233, -0.0465, -0.0233],\n",
      "          [ 0.0465,  0.0000, -0.0000],\n",
      "          [ 0.0930,  0.1163,  0.0233]],\n",
      "\n",
      "         [[-0.0000, -0.0465, -0.0465],\n",
      "          [ 0.0465,  0.0465,  0.0465],\n",
      "          [-0.0698,  0.0465,  0.0465]],\n",
      "\n",
      "         [[ 0.0698, -0.0465, -0.0465],\n",
      "          [-0.0233,  0.0698, -0.0233],\n",
      "          [ 0.0000,  0.0698, -0.0233]]],\n",
      "\n",
      "\n",
      "        [[[-0.0233,  0.0000,  0.0000],\n",
      "          [-0.0465,  0.0465, -0.0233],\n",
      "          [ 0.0233,  0.0465,  0.0233]],\n",
      "\n",
      "         [[ 0.0000,  0.0698,  0.0233],\n",
      "          [-0.0233,  0.0465,  0.0000],\n",
      "          [-0.0698, -0.0465, -0.0698]],\n",
      "\n",
      "         [[ 0.0465,  0.0233, -0.0465],\n",
      "          [ 0.0233,  0.1163,  0.0698],\n",
      "          [ 0.0465,  0.0465, -0.0233]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0465,  0.0465],\n",
      "          [-0.0698,  0.1163,  0.1163],\n",
      "          [ 0.0233,  0.1395,  0.1628]],\n",
      "\n",
      "         [[-0.0233,  0.0000,  0.0000],\n",
      "          [-0.0465, -0.0465,  0.0698],\n",
      "          [ 0.0233,  0.0233,  0.0465]],\n",
      "\n",
      "         [[-0.0465,  0.0465,  0.0930],\n",
      "          [-0.0233,  0.1163,  0.0698],\n",
      "          [ 0.0465, -0.0233,  0.0465]]],\n",
      "\n",
      "\n",
      "        [[[-0.0465, -0.0000,  0.0233],\n",
      "          [ 0.0233,  0.0465,  0.0465],\n",
      "          [ 0.0465,  0.0465,  0.0465]],\n",
      "\n",
      "         [[-0.0000, -0.0465, -0.0233],\n",
      "          [-0.0000, -0.0233,  0.0233],\n",
      "          [ 0.0233,  0.0000,  0.0233]],\n",
      "\n",
      "         [[ 0.0465,  0.0233, -0.0465],\n",
      "          [-0.0465,  0.0233,  0.0000],\n",
      "          [ 0.0233, -0.0698, -0.0465]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0465, -0.0000,  0.0233],\n",
      "          [-0.0465, -0.0233, -0.0233],\n",
      "          [ 0.0465,  0.0233, -0.0465]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0233],\n",
      "          [-0.0233, -0.0233,  0.0465],\n",
      "          [-0.0465, -0.0465, -0.0233]],\n",
      "\n",
      "         [[ 0.0000,  0.0233,  0.0000],\n",
      "          [-0.0233, -0.0465, -0.0000],\n",
      "          [-0.0233,  0.0465, -0.0465]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0465, -0.0233, -0.0465],\n",
      "          [-0.0000, -0.0233,  0.0233],\n",
      "          [-0.0233,  0.0465, -0.0465]],\n",
      "\n",
      "         [[-0.0465,  0.0465, -0.0233],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0465,  0.0000, -0.0465]],\n",
      "\n",
      "         [[ 0.0930,  0.0233,  0.0465],\n",
      "          [ 0.0930,  0.0698,  0.0233],\n",
      "          [ 0.0465, -0.0930, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.0930, -0.0698],\n",
      "          [ 0.1163,  0.1395,  0.0698],\n",
      "          [ 0.0465,  0.1163, -0.0698]],\n",
      "\n",
      "         [[-0.0698, -0.0000,  0.0233],\n",
      "          [-0.0465, -0.0233,  0.0233],\n",
      "          [ 0.0233,  0.0233,  0.0233]],\n",
      "\n",
      "         [[ 0.0000,  0.0465,  0.0465],\n",
      "          [ 0.0465,  0.0233,  0.0698],\n",
      "          [-0.0465, -0.0233, -0.0930]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0465,  0.0465],\n",
      "          [-0.0465,  0.0233,  0.0465],\n",
      "          [ 0.0465,  0.0233,  0.0233]],\n",
      "\n",
      "         [[ 0.0000,  0.0233, -0.0000],\n",
      "          [-0.0465,  0.0465, -0.0465],\n",
      "          [ 0.0465,  0.0000,  0.0233]],\n",
      "\n",
      "         [[ 0.0000,  0.0233,  0.0465],\n",
      "          [-0.0465,  0.0233, -0.0233],\n",
      "          [-0.0465, -0.0465,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0465,  0.0000,  0.0233],\n",
      "          [-0.0000, -0.0000, -0.0698],\n",
      "          [-0.0233, -0.0698,  0.0465]],\n",
      "\n",
      "         [[ 0.0465, -0.0465, -0.0465],\n",
      "          [-0.0465,  0.0233,  0.0000],\n",
      "          [-0.0465, -0.0233,  0.0465]],\n",
      "\n",
      "         [[-0.0000, -0.0465,  0.0233],\n",
      "          [ 0.0465,  0.0465,  0.0000],\n",
      "          [-0.0233,  0.0000,  0.0465]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0233, -0.0465,  0.0233],\n",
      "          [ 0.0465, -0.0465, -0.0465],\n",
      "          [ 0.0465,  0.0233, -0.0465]],\n",
      "\n",
      "         [[ 0.0233,  0.0465,  0.0233],\n",
      "          [ 0.0233,  0.0233,  0.0233],\n",
      "          [ 0.0233, -0.0233,  0.0000]],\n",
      "\n",
      "         [[-0.0233, -0.0000,  0.0233],\n",
      "          [-0.0233, -0.0000,  0.0465],\n",
      "          [ 0.0233,  0.0698, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0233, -0.0465,  0.0465],\n",
      "          [-0.0233, -0.0000,  0.0233],\n",
      "          [ 0.0233, -0.0233, -0.0000]],\n",
      "\n",
      "         [[-0.0465, -0.0233, -0.0233],\n",
      "          [ 0.0000, -0.0233,  0.0233],\n",
      "          [-0.0000, -0.0465,  0.0233]],\n",
      "\n",
      "         [[-0.0233,  0.0465, -0.0000],\n",
      "          [ 0.0465,  0.0465,  0.0465],\n",
      "          [ 0.0000,  0.0465, -0.0000]]]], device='cuda:0'), scale=tensor(0.0233, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32, 32, 3, 3]),\n",
      "bias_1 = QuantTensor(value=tensor([ 0.0215, -0.0000, -0.0430, -0.0752, -0.0430, -0.0322, -0.0430,  0.0645,\n",
      "        -0.0537, -0.0215,  0.0107,  0.0000, -0.0107,  0.0215,  0.0000,  0.0430,\n",
      "        -0.0215,  0.0752, -0.0537, -0.0537,  0.0215, -0.0215, -0.0107,  0.0322,\n",
      "         0.0215,  0.0645,  0.0215,  0.0322, -0.0107,  0.0107, -0.0215,  0.0215],\n",
      "       device='cuda:0'), scale=tensor(0.0107, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32])\n",
      "weight_2 = QuantTensor(value=tensor([[[[ 0.0354, -0.0354,  0.0000],\n",
      "          [ 0.0708, -0.0000, -0.0708],\n",
      "          [-0.0708,  0.0000, -0.0354]],\n",
      "\n",
      "         [[-0.0354,  0.0354, -0.0354],\n",
      "          [-0.0354,  0.0354,  0.0354],\n",
      "          [ 0.0354,  0.0708,  0.0000]],\n",
      "\n",
      "         [[ 0.0354, -0.0354, -0.0354],\n",
      "          [ 0.0000, -0.0354, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0354, -0.0354, -0.0354],\n",
      "          [-0.0000,  0.0000, -0.0354],\n",
      "          [ 0.0000,  0.0000, -0.0354]],\n",
      "\n",
      "         [[ 0.0000,  0.0354,  0.0354],\n",
      "          [ 0.0354, -0.0354, -0.0354],\n",
      "          [ 0.0354,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0354, -0.0354, -0.0708],\n",
      "          [-0.0354, -0.0708,  0.0354],\n",
      "          [ 0.0354, -0.0354, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0354, -0.0354],\n",
      "          [ 0.0354, -0.0354, -0.0354],\n",
      "          [ 0.0000, -0.0354,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0354],\n",
      "          [-0.0708, -0.0354,  0.0708],\n",
      "          [-0.0000, -0.0354,  0.0354]],\n",
      "\n",
      "         [[ 0.0354,  0.0354, -0.0354],\n",
      "          [ 0.0708, -0.0354, -0.0708],\n",
      "          [ 0.0000, -0.0000, -0.0708]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0354, -0.0708, -0.0354],\n",
      "          [ 0.0708, -0.0354,  0.0354],\n",
      "          [-0.0354, -0.0354,  0.0708]],\n",
      "\n",
      "         [[-0.0000, -0.0354, -0.0354],\n",
      "          [-0.0354,  0.0354, -0.0354],\n",
      "          [-0.0354,  0.0354,  0.0354]],\n",
      "\n",
      "         [[-0.0354,  0.0000, -0.0000],\n",
      "          [ 0.0354, -0.0354, -0.0354],\n",
      "          [ 0.0354,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0354,  0.0354, -0.0354],\n",
      "          [ 0.0354,  0.0354, -0.0000],\n",
      "          [-0.0354,  0.0354,  0.0354]],\n",
      "\n",
      "         [[-0.0708, -0.0708, -0.0000],\n",
      "          [-0.0354, -0.0354,  0.0354],\n",
      "          [ 0.0000,  0.0354,  0.0000]],\n",
      "\n",
      "         [[ 0.0708,  0.0354,  0.0000],\n",
      "          [ 0.0354, -0.0354,  0.0354],\n",
      "          [ 0.0000,  0.0708, -0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0354, -0.0354,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0354,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0354, -0.0354, -0.0354],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0354,  0.0354,  0.0708]],\n",
      "\n",
      "         [[ 0.0354,  0.0000, -0.0354],\n",
      "          [-0.0354, -0.0354, -0.0000],\n",
      "          [-0.0354,  0.0354, -0.0708]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0708, -0.0354, -0.0000],\n",
      "          [-0.0000, -0.0354, -0.0000],\n",
      "          [ 0.0354, -0.0354,  0.0354]],\n",
      "\n",
      "         [[-0.0354,  0.0000,  0.0000],\n",
      "          [-0.0354, -0.0354, -0.0354],\n",
      "          [-0.0354,  0.0000, -0.0354]],\n",
      "\n",
      "         [[ 0.0708,  0.0000, -0.0354],\n",
      "          [-0.0354,  0.0354, -0.0000],\n",
      "          [ 0.0354,  0.0354, -0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0354, -0.0708,  0.0000],\n",
      "          [ 0.0354,  0.0000, -0.0354],\n",
      "          [-0.0354,  0.0000,  0.0354]],\n",
      "\n",
      "         [[-0.0354,  0.0354, -0.0354],\n",
      "          [ 0.0000,  0.0354, -0.0354],\n",
      "          [ 0.0354,  0.0000, -0.0354]],\n",
      "\n",
      "         [[-0.0354,  0.0354,  0.0354],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0354,  0.0354, -0.0354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0354,  0.0354, -0.0000],\n",
      "          [-0.0354, -0.0354,  0.0354],\n",
      "          [-0.0000, -0.0354, -0.0354]],\n",
      "\n",
      "         [[ 0.0000,  0.0354, -0.0354],\n",
      "          [ 0.0000, -0.0354, -0.0354],\n",
      "          [-0.0354,  0.0354, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0354,  0.0000],\n",
      "          [ 0.0354, -0.0354,  0.0000],\n",
      "          [ 0.0354, -0.0708,  0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0354, -0.0708],\n",
      "          [-0.0000, -0.0708,  0.0354],\n",
      "          [-0.0354,  0.0000,  0.0354]],\n",
      "\n",
      "         [[-0.0354, -0.0000, -0.0354],\n",
      "          [-0.0000,  0.0354,  0.0354],\n",
      "          [ 0.0354, -0.0354, -0.0354]],\n",
      "\n",
      "         [[-0.0354, -0.0354,  0.0354],\n",
      "          [-0.0354,  0.0354, -0.0354],\n",
      "          [ 0.0000,  0.0000,  0.0354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0708, -0.0708,  0.0354],\n",
      "          [ 0.0354,  0.0354,  0.0708],\n",
      "          [-0.0354,  0.0708,  0.0000]],\n",
      "\n",
      "         [[ 0.0354, -0.1416,  0.0000],\n",
      "          [-0.0708,  0.1062, -0.0000],\n",
      "          [ 0.0708, -0.0000, -0.1062]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0708],\n",
      "          [-0.0354,  0.0354, -0.0708],\n",
      "          [-0.0354, -0.0354, -0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1062, -0.1062, -0.0354],\n",
      "          [-0.0708, -0.0354,  0.0354],\n",
      "          [ 0.1062,  0.0708,  0.0708]],\n",
      "\n",
      "         [[ 0.0708,  0.0354, -0.0354],\n",
      "          [ 0.0354,  0.0354,  0.0354],\n",
      "          [-0.0000,  0.0000, -0.0354]],\n",
      "\n",
      "         [[ 0.0354,  0.0354, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0354, -0.0000]]]], device='cuda:0'), scale=tensor(0.0354, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32, 32, 3, 3]),\n",
      "bias_2 = QuantTensor(value=tensor([-0.0138,  0.0415, -0.0415, -0.0553,  0.0553, -0.0553,  0.0276,  0.0138,\n",
      "        -0.0276, -0.0553,  0.0000, -0.0138,  0.0415,  0.0415,  0.0000,  0.0829,\n",
      "         0.0276,  0.0138, -0.0276,  0.0276, -0.0276, -0.0000, -0.0415,  0.0415,\n",
      "         0.0415,  0.0415, -0.0553,  0.0138, -0.1106, -0.0276,  0.0000,  0.0553],\n",
      "       device='cuda:0'), scale=tensor(0.0138, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32])\n",
      "weight_3 = QuantTensor(value=tensor([[[[-0.0000,  0.0548,  0.0000],\n",
      "          [ 0.0000,  0.0548, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.1096,  0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0548],\n",
      "          [ 0.0000,  0.0000, -0.0548]],\n",
      "\n",
      "         [[-0.0548, -0.0548,  0.0548],\n",
      "          [ 0.0548, -0.0548, -0.0548],\n",
      "          [-0.0548,  0.0548,  0.0548]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548, -0.0548,  0.0548],\n",
      "          [-0.0000,  0.0548, -0.0000],\n",
      "          [-0.0000,  0.0548,  0.0548]],\n",
      "\n",
      "         [[-0.0000,  0.0548, -0.0548],\n",
      "          [-0.0548,  0.0000,  0.0548],\n",
      "          [ 0.0000,  0.0548,  0.0548]],\n",
      "\n",
      "         [[ 0.1644, -0.0548, -0.2192],\n",
      "          [-0.1644, -0.1096,  0.1096],\n",
      "          [ 0.0548,  0.1644, -0.1096]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0548, -0.0548],\n",
      "          [ 0.0000, -0.0000, -0.0548],\n",
      "          [ 0.0000,  0.0000, -0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548,  0.0548],\n",
      "          [-0.0000, -0.0548, -0.0548],\n",
      "          [-0.0548, -0.0548,  0.0548]],\n",
      "\n",
      "         [[ 0.0548, -0.0000,  0.0000],\n",
      "          [-0.0548, -0.0000,  0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0548]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0548, -0.0548,  0.0548],\n",
      "          [-0.0548,  0.0000,  0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548, -0.0000],\n",
      "          [-0.0548, -0.0548, -0.0000],\n",
      "          [-0.0548, -0.0548,  0.0000]],\n",
      "\n",
      "         [[ 0.0548,  0.0000,  0.0000],\n",
      "          [-0.0548,  0.0000,  0.0000],\n",
      "          [ 0.0548, -0.0548,  0.0548]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.0000, -0.0548],\n",
      "          [ 0.0000,  0.0548, -0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548,  0.0000],\n",
      "          [-0.0548, -0.0548,  0.0548],\n",
      "          [ 0.0000,  0.0548,  0.0000]],\n",
      "\n",
      "         [[ 0.0548, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0548],\n",
      "          [-0.0000,  0.0548, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.0548,  0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0548]],\n",
      "\n",
      "         [[-0.0548, -0.0548, -0.0000],\n",
      "          [-0.0000, -0.0548, -0.0000],\n",
      "          [-0.0000,  0.0548, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0548,  0.0000,  0.0548],\n",
      "          [-0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0548, -0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0548, -0.0548,  0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0548],\n",
      "          [ 0.0548,  0.0000,  0.0548]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0548],\n",
      "          [-0.0000,  0.0000,  0.0548]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0548],\n",
      "          [-0.0000,  0.0548, -0.0000],\n",
      "          [-0.0548,  0.0548,  0.0000]],\n",
      "\n",
      "         [[-0.0548, -0.0548, -0.0000],\n",
      "          [-0.0548, -0.0548, -0.1096],\n",
      "          [ 0.0000, -0.1096, -0.0548]]],\n",
      "\n",
      "\n",
      "        [[[-0.0548,  0.0548, -0.0000],\n",
      "          [-0.0000,  0.0548, -0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0548, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0548, -0.0000],\n",
      "          [ 0.0548,  0.0548, -0.0548]],\n",
      "\n",
      "         [[ 0.0000,  0.0548,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0548],\n",
      "          [ 0.0548, -0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548,  0.0000,  0.0000],\n",
      "          [-0.0548, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0548, -0.0548]],\n",
      "\n",
      "         [[ 0.0000, -0.0548, -0.0000],\n",
      "          [ 0.0548,  0.0548,  0.0548],\n",
      "          [ 0.0000,  0.0548, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0548],\n",
      "          [ 0.0000,  0.0548, -0.0000],\n",
      "          [ 0.0000, -0.1096, -0.1096]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.0000, -0.0548],\n",
      "          [ 0.0548, -0.0000, -0.0548],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0548, -0.0548,  0.0000],\n",
      "          [ 0.0548,  0.0548, -0.0548],\n",
      "          [-0.0000, -0.0548,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0548,  0.0548,  0.0548],\n",
      "          [ 0.0000, -0.0548, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548,  0.0000, -0.0000],\n",
      "          [-0.0548, -0.0548,  0.0548],\n",
      "          [-0.0548, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0548,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0548],\n",
      "          [-0.0548,  0.0548,  0.0000]],\n",
      "\n",
      "         [[-0.1644, -0.1096,  0.1096],\n",
      "          [ 0.1096,  0.0548, -0.1644],\n",
      "          [-0.0000, -0.0548, -0.0548]]]], device='cuda:0'), scale=tensor(0.0548, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32, 32, 3, 3]),\n",
      "bias_3 = QuantTensor(value=tensor([ 0.0375, -0.0000, -0.0375, -0.0562,  0.0937,  0.0375, -0.0375,  0.0562,\n",
      "         0.1124,  0.0000, -0.0187,  0.1124, -0.0187,  0.0562,  0.0375, -0.0375,\n",
      "        -0.0187, -0.0562,  0.0375,  0.0187, -0.0375, -0.0562, -0.0375,  0.0749,\n",
      "         0.0749, -0.0187,  0.1311, -0.0000, -0.0000, -0.0187,  0.0187, -0.0187],\n",
      "       device='cuda:0'), scale=tensor(0.0187, device='cuda:0'), zero_point=tensor(0., device='cuda:0'), bit_width=tensor(4., device='cuda:0'), signed_t=tensor(True), training_t=tensor(False)), shape = torch.Size([32])\n",
      "torch.Size([10, 288])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_dicts_float: List[Dict[str, torch.Tensor]] = []\n",
    "state_dicts_quant: List[Dict[str, torch.Tensor]] = []\n",
    "state_dicts_quant_2: List[Dict[str, torch.Tensor]] = []\n",
    "sd_fc = net.FC.state_dict()\n",
    "sd_fc_2 = sd_fc\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, L in enumerate(net.conv_layers):\n",
    "        L: QuantConv2d = L\n",
    "        state_dicts_float.append({\"state\": L.state_dict})\n",
    "        state_dicts_quant.append({\"weight\": L.quant_weight()[0], \"bias\" : L.quant_bias()[0]})\n",
    "\n",
    "        print(f\"weight_{i} = {L.quant_weight()}, shape = {L.quant_weight().shape},\\nbias_{i} = {L.quant_bias()}, shape = {L.quant_bias().shape}\")\n",
    "\n",
    "    state_dicts_quant_2 = deepcopy(state_dicts_quant)\n",
    "\n",
    "print(sd_fc[\"weight\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(parameter: torch.Tensor, threshold: float):\n",
    "    \"\"\"\n",
    "    Function returns the mask of filters which should not be removed. \n",
    "\n",
    "    :param parameter: weight tensor with shape = (num_of_filters, input_channels, Optional[kernel_height, kernel_width]]\n",
    "    :param threshold float: threshold value - cos of \"angle\" between filters \n",
    "    :return: tensor - bool mask\n",
    "    \"\"\"\n",
    "    original_shape = parameter.shape\n",
    "    parameter = parameter.reshape(original_shape[0],-1)\n",
    "    parameter = parameter / (parameter.square().sum(1).reshape(-1,1).sqrt())\n",
    "    \n",
    "    # correlation matrix\n",
    "    corr = torch.matmul(parameter, parameter.transpose(0,1))\n",
    "    \n",
    "    # highly correlated filters mask \n",
    "    corr_mask = corr.abs() > threshold\n",
    "\n",
    "    # print(corr.shape)\n",
    "    \n",
    "    # over diagonal matrix\n",
    "    row_idx, col_idx = torch.meshgrid(torch.arange(0,corr.shape[0]), torch.arange(0,corr.shape[0]),)\n",
    "    analysis_mask = col_idx > row_idx\n",
    "    \n",
    "    # over diagonal part of mask\n",
    "    filters_correlation = corr_mask * analysis_mask.to(parameter.device)\n",
    "\n",
    "    channels_mask = filters_correlation.sum(0) == 0\n",
    "    \n",
    "    return channels_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate pruning masks (`get_mask`) for each quantized weights from `state_dicts_quant` list.\n",
    "\n",
    "Store them in list `masks`.\n",
    "\n",
    "Calculate number of filters of convolutional layers after pruning for each layer\n",
    "\n",
    "and print it.\n",
    "\n",
    "Use thresholds for next CNN layers: `thresholds = [0.5, 0.5, 0.5, 0.5]`\n",
    "\n",
    "Hint: work on copy of weights - `torch.Tensor.clone` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: filters after pruning: 5\n",
      "Layer 1: filters after pruning: 32\n",
      "Layer 2: filters after pruning: 26\n",
      "Layer 3: filters after pruning: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsriw/anaconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "masks: List[torch.Tensor] = []\n",
    "num_of_filters_after_pruning = nofp = []\n",
    "thresholds = [0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "for i, (sd_q, th) in enumerate(zip(state_dicts_quant, thresholds)):\n",
    "    w = sd_q['weight']\n",
    "    mask = get_mask(w, th)\n",
    "    \n",
    "    masks.append(mask)\n",
    "    num_of_filters_after_pruning.append(mask.sum())\n",
    "    \n",
    "    print(f\"Layer {i}: filters after pruning: {nofp[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Slice weights and biases from `state_dicts_quant` based on created `masks`.\n",
    "\n",
    "Results assign to proper indices and keys of `state_dicts_quant_2`.\n",
    "\n",
    "Slice weight of fc layer from `sd_fc` and result assign to `sd_fc_2` based on last mask.\n",
    "\n",
    "Print shapes of weights and biases.\n",
    "\n",
    "Note: Pruning of channels one layer affects to next one layer, but not to the previous layer.\n",
    "\n",
    "Note: bias is related with layer output channel.\n",
    "\n",
    "Note: first layer must contain the same number of input channels.\n",
    "\n",
    "Hint: For slicing of few dimensions, use it separately on results of previous dim slice.\n",
    "\n",
    "Hint: Do it in loop: store mask for previous mask as variable like `prev_mask`.\n",
    "\n",
    "For init `prev_mask` use tensor of True and shape (1,) - input channels.\n",
    "\n",
    "Note: Fc layer is forwarded by flatten layer ((BS,CH,H,W) -> (BS, CH * H * W)), \n",
    "\n",
    "so the input mask should be properly modified:\n",
    "\n",
    "```fc_in_mask = prev_mask.reshape(-1,1,1).tile(1,H,W).flatten()```\n",
    "\n",
    "CH,H,W sizes are printed, when the network is instantiated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: weight: torch.Size([5, 1, 3, 3])\n",
      "Layer 0: bias: torch.Size([5])\n",
      "Layer 1: weight: torch.Size([32, 5, 3, 3])\n",
      "Layer 1: bias: torch.Size([32])\n",
      "Layer 2: weight: torch.Size([26, 32, 3, 3])\n",
      "Layer 2: bias: torch.Size([26])\n",
      "Layer 3: weight: torch.Size([31, 26, 3, 3])\n",
      "Layer 3: bias: torch.Size([31])\n",
      "Layer FC: weight: torch.Size([10, 288])\n",
      "Layer FC: bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "prev_mask = torch.ones((1,), dtype=torch.bool, device=device)\n",
    "\n",
    "for i, (mask, sd_q, sd_q_2) in enumerate(zip(masks, state_dicts_quant, state_dicts_quant_2)):\n",
    "    w = sd_q[\"weight\"][mask, :][:, prev_mask]\n",
    "    b = sd_q[\"bias\"][mask]\n",
    "\n",
    "    sd_q_2[\"weight\"] = w\n",
    "    sd_q_2[\"bias\"] = b\n",
    "\n",
    "    print(f\"Layer {i}: weight: {w.shape}\")\n",
    "    print(f\"Layer {i}: bias: {b.shape}\")\n",
    "    prev_mask = mask.clone()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fc_in_mask = prev_mask.reshape(-1,1,1).tile(1,3,3).flatten()\n",
    "\n",
    "\n",
    "\n",
    "w = sd_fc[\"weight\"]\n",
    "b = sd_fc[\"bias\"]\n",
    "sd_fc_2['weight'] = sd_fc[\"weight\"][:, fc_in_mask]\n",
    "\n",
    "print(f\"Layer FC: weight: {w.shape}\")\n",
    "print(f\"Layer FC: bias: {b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Instantiate second `NeuralNetwork` as `net_2` with channels number defined by `num_of_filters_after_pruning`.\n",
    "\n",
    "Initialize conv subnetwork (`net_2.conv_layers`) with state dicts from `state_dicts_quant_2`.\n",
    "\n",
    "Initialize FC layer with `sd_fc_2`.\n",
    "\n",
    "Print number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN out map shape = [tensor(31, device='cuda:0'), 3, 3]\n",
      "CNN out map numel = 279\n",
      "Network parameters number: 19126\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "net_2 = NeuralNetwork(input_shape=(1,28,28), \n",
    "                      num_of_classes=10,\n",
    "                      channels = nofp, # number of conv filters \n",
    "                      ksize   =  [3, 3, 3, 3], # kernels sizes\n",
    "                      padding =  [1, 1, 0, 0], # padding sizes\n",
    "                      max_pool = [1, 1, 0, 0], # use maxpool after conv or not\n",
    "                      quantize=True\n",
    "                      ).to(device)\n",
    "for layer, st2 in zip(net_2.conv_layers, state_dicts_quant_2):\n",
    "    layer.load_state_dict(st2)\n",
    "\n",
    "net_2.FC.load_state_dict(sd_fc_2)\n",
    "\n",
    "net_2_param_number = lu.count_params(net_2)\n",
    "\n",
    "print(f\"Network parameters number: {net_2_param_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate accuracy and loss for training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:13, 68.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.070917551676432 0.6221833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:02, 69.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.067455157470703 0.6295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lu.train_test_pass(net_2,\n",
    "                               train_loader,\n",
    "                               criterion,\n",
    "                               metric,\n",
    "                               optimizer=None,\n",
    "                               update_period=None,\n",
    "                               mode='test',\n",
    "                               device=device)[1:]\n",
    "print(loss, acc)\n",
    "loss, acc = lu.train_test_pass(net_2,\n",
    "                               test_loader,\n",
    "                               criterion,\n",
    "                               metric,\n",
    "                               optimizer=None,\n",
    "                               update_period=None,\n",
    "                               mode='test',\n",
    "                               device=device)[1:]\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. *Aditional: Try 5 different thresholds setting (5 lists of settings) for `get_mask` function.\n",
    "\n",
    "Print resulted sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Additional: Fine tune pruned model (`net_2`) - train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. You can leave a feedback, if you want :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Exercises please upload this file (*.ipynb) to UPEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f8983bddda93f81dfa77202df1e7f4d1cde96e239aa7ad80697fb7e3c19a16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
